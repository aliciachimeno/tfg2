%%TC:ignore
\documentclass[../../main.tex]{subfiles}

\begin{document}

\chapter*{Abstract}\label{ch:abstract} \addcontentsline{toc}{chapter}{\nameref{ch:abstract}}
Exemple d'abstract no definitiu, x ficar algo.  \\ \\ 
The Leshno-Lin-Pinkus-Schocken (LLPS) theorem is a seminal result in the field of neural network theory. It states that multilayer feedforward neural networks with a nonpolynomial activation function can approximate any function to any desired level of accuracy, provided that the network has a sufficient number of hidden units. In this thesis, we present a detailed proof of the LLPS theorem, along with an explanation of its significance and implications for the design and training of neural networks


\chapter*{Resum}

blslalblallb en catal√†
\end{document}
%%TC:endignore