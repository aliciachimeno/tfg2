%%TC:ignore
\documentclass[../../main.tex]{subfiles}

\begin{document}

\chapter*{Abstract}\label{ch:abstract} \addcontentsline{toc}{chapter}{\nameref{ch:abstract}}
\noindent 

In today's world, many people employ machine learning models, yet only a few understand the underlying mathematics that support them. 
How we can find a predictive function from a given dataset and ascertain the existence of such a function? This research seeks to address these concerns by exploring the mathematical foundations of function approximation in machine learning. Especially focus on function approximation using neural networks. Our research 



presents a significant finding, demonstrating that a multilayer feedforward network equipped with a non-polynomial activation function can effectively approximate any continuous function. Through this study, we aim to bridge the gap between the practical application of machine learning and the mathematical principles that underpin its success.

%This study explores the mathematical foundations of machine learning and focuses on function approximation using neural networks. We propose a general finding that a multilayer feedforward network employing a non polynomial activation can accurately approximate any continuous function. 

\chapter*{Resum}



blslalblallb en catal√†
\end{document}
%%TC:endignore