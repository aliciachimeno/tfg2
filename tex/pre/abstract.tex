%%TC:ignore
\documentclass[../../main.tex]{subfiles}

\begin{document}



\section*{Abstract} % starred section doesn't get the correct header


\noindent In today's world, many people employ machine learning models, yet the mathematical principles underlying their success are not completely understood. In this work, our approach to machine learning will incorporate an analytical perspective, emphasizing function approximation as a core component. How can we ensure the existence of a predictive function from a given dataset? This research seeks to address these concerns by exploring the mathematical foundations of function approximation in machine learning, with a specific focus on neural networks.
\\ \\
In particular, we delve into a significant finding, the theorem proved by Leshno-Lin-Pinkus-Schonken in 1993 \cite{leshno1993multilayer}, which states that a multilayer feedforward network equipped with a non-polynomial activation function can effectively approximate any continuous function. Our work revolves around understanding and reinterpreting the proof, while expanding and providing further details.
Through this study, we aim to bridge the gap between the practical application of machine learning and the mathematical principles that underpin its success.

\newpage

\section*{Resum}
\newpage
\section*{Preface}



blslalblallb en catal√†
\end{document}
%%TC:endignore